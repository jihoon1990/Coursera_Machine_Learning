{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting house prices using k-nearest neighbors regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will implement k-nearest neighbors regression. You will:\n",
    "* Find the k-nearest neighbors of a given query input\n",
    "* Predict the output for the query input using the k-nearest neighbors\n",
    "* Choose the best value of k using a validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtype_dict = {'bathrooms':float, 'waterfront':int, 'sqft_above':int, \n",
    "              'sqft_living15':float, 'grade':int, 'yr_renovated':int, \n",
    "              'price':float, 'bedrooms':float, 'zipcode':str, 'long':float, \n",
    "              'sqft_lot15':float, 'sqft_living':float, 'floors':str, \n",
    "              'condition':int, 'lat':float, 'date':str, 'sqft_basement':int, \n",
    "              'yr_built':int, 'id':str, 'sqft_lot':int, 'view':int}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data from CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales = pd.read_csv(\"kc_house_data_small.csv\", dtype = dtype_dict)\n",
    "train_data = pd.read_csv(\"kc_house_data_small_train.csv\", dtype = dtype_dict)\n",
    "test_data = pd.read_csv(\"kc_house_data_small_test.csv\", dtype = dtype_dict)\n",
    "valid_data = pd.read_csv(\"kc_house_data_validation.csv\", dtype = dtype_dict)\n",
    "\n",
    "# In the dataset, 'floors' was defined with type string, \n",
    "# so we'll convert them to int, before using it below\n",
    "sales['floors'] = sales['floors'].astype(float)\n",
    "sales['constant'] = 1\n",
    "train_data['floors'] = train_data['floors'].astype(float)\n",
    "train_data['constant'] = 1\n",
    "test_data['floors'] = test_data['floors'].astype(float)\n",
    "test_data['constant'] = 1\n",
    "valid_data['floors'] = valid_data['floors'].astype(float)\n",
    "valid_data['constant'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import useful functions from previous work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_features(features):\n",
    "    norms = np.linalg.norm(features, axis = 0)\n",
    "    X_normalized = features / norms\n",
    "    return(X_normalized, norms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list = ['constant',\n",
    "                'bedrooms',  \n",
    "                'bathrooms',  \n",
    "                'sqft_living',  \n",
    "                'sqft_lot',  \n",
    "                'floors',\n",
    "                'waterfront',  \n",
    "                'view',  \n",
    "                'condition',  \n",
    "                'grade',  \n",
    "                'sqft_above',  \n",
    "                'sqft_basement',\n",
    "                'yr_built',  \n",
    "                'yr_renovated',  \n",
    "                'lat',  \n",
    "                'long',  \n",
    "                'sqft_living15',  \n",
    "                'sqft_lot15']\n",
    "\n",
    "features_train = train_data[feature_list].as_matrix()\n",
    "output_train = train_data['price'].as_matrix()\n",
    "features_test = test_data[feature_list].as_matrix()\n",
    "output_test = test_data['price'].as_matrix()\n",
    "features_valid = valid_data[feature_list].as_matrix()\n",
    "output_valid = valid_data['price'].as_matrix()\n",
    "\n",
    "features_train, norms = normalize_features(features_train) # normalize training set features (columns)\n",
    "features_test = features_test / norms # normalize test set by training set norms\n",
    "features_valid = features_valid / norms # normalize validation set by training set norms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In computing distances, it is crucial to normalize features. Otherwise, for example, the sqft_living feature (typically on the order of thousands) would exert a much larger influence on distance than the bedrooms feature (typically on the order of ones). We divide each column of the training feature matrix by its 2-norm, so that the transformed column has unit norm.\n",
    "\n",
    "IMPORTANT: Make sure to store the norms of the features in the training set. The features in the test and validation sets must be divided by these same norms, so that the training, test, and validation sets are normalized consistently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute a single distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, let's just explore computing the \"distance\" between two given houses. We will take our **query house** to be the first house of the test set and look at the distance between this house and the 10th house of the training set.\n",
    "To see the features associated with the query house, print the first row (index 0) of the test feature matrix. You should get an 18-dimensional vector whose components are between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query House:  [ 0.01345102  0.01551285  0.01807473  0.01759212  0.00160518  0.017059    0.\n",
      "  0.05102365  0.0116321   0.01564352  0.01362084  0.02481682  0.01350306\n",
      "  0.          0.01345387 -0.01346922  0.01375926  0.0016225 ]\n",
      "\n",
      "10th House:  [ 0.01345102  0.01163464  0.00602491  0.0083488   0.00050756  0.01279425\n",
      "  0.          0.          0.01938684  0.01390535  0.0096309   0.\n",
      "  0.01302544  0.          0.01346821 -0.01346251  0.01195898  0.00156612]\n",
      "\n",
      "Euclidian Distance of Query House and 10th House in Train set:  0.059723593714\n"
     ]
    }
   ],
   "source": [
    "print(\"Query House: \", features_test[0])\n",
    "print(\"\\n10th House: \", features_train[9])\n",
    "euclidian_distance = np.sqrt(np.sum((features_test[0] - features_train[9])**2))\n",
    "print(\"\\nEuclidian Distance of Query House and 10th House in Train set: \", euclidian_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute multiple distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance from first 10 data: \n",
      "0 0.060274709163\n",
      "1 0.0854688114764\n",
      "2 0.0614994643528\n",
      "3 0.0534027397929\n",
      "4 0.0584448406017\n",
      "5 0.0598792150981\n",
      "6 0.0546314049678\n",
      "7 0.0554310832361\n",
      "8 0.0523836278402\n",
      "9 0.059723593714\n",
      "Closest data:  (8, 0.052383627840220305)\n"
     ]
    }
   ],
   "source": [
    "print(\"Distance from first 10 data: \")\n",
    "dist_dict = {}\n",
    "for i in range(0,10):\n",
    "    dist_dict[i] = np.sqrt(np.sum((features_train[i] - features_test[0])**2))\n",
    "    print (i, np.sqrt(np.sum((features_train[i] - features_test[0])**2)))\n",
    "    \n",
    "closest = min(dist_dict.items(), key=lambda x: x[1])\n",
    "print(\"Closest data: \", closest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is computationally inefficient to loop over computing distances to all houses in our training dataset. Fortunately, many of the Numpy functions can be **vectorized**, applying the same operation over multiple values or vectors. We now walk through this process.\n",
    "\n",
    "Consider the following loop that computes the element-wise difference between the features of the query house (`features_test[0]`) and the first 3 training houses (`features_train[0:3]`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.00000000e+00  -3.87821276e-03  -1.20498190e-02  -1.05552733e-02\n",
      "   2.08673616e-04  -8.52950206e-03   0.00000000e+00  -5.10236549e-02\n",
      "   0.00000000e+00  -3.47633726e-03  -5.50336860e-03  -2.48168183e-02\n",
      "  -1.63756198e-04   0.00000000e+00  -1.70254220e-05   1.29876855e-05\n",
      "  -5.14364795e-03   6.69281453e-04]\n",
      "[  0.00000000e+00  -3.87821276e-03  -4.51868214e-03  -2.26610387e-03\n",
      "   7.19763456e-04   0.00000000e+00   0.00000000e+00  -5.10236549e-02\n",
      "   0.00000000e+00  -3.47633726e-03   1.30705004e-03  -1.45830788e-02\n",
      "  -1.91048898e-04   6.65082271e-02   4.23090220e-05   6.16364736e-06\n",
      "  -2.89330197e-03   1.47606982e-03]\n",
      "[  0.00000000e+00  -7.75642553e-03  -1.20498190e-02  -1.30002801e-02\n",
      "   1.60518166e-03  -8.52950206e-03   0.00000000e+00  -5.10236549e-02\n",
      "   0.00000000e+00  -5.21450589e-03  -8.32384500e-03  -2.48168183e-02\n",
      "  -3.13866046e-04   0.00000000e+00   4.70885840e-05   1.56292487e-05\n",
      "   3.72914476e-03   1.64764925e-03]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,  -3.87821276e-03,  -1.20498190e-02,\n",
       "         -1.05552733e-02,   2.08673616e-04,  -8.52950206e-03,\n",
       "          0.00000000e+00,  -5.10236549e-02,   0.00000000e+00,\n",
       "         -3.47633726e-03,  -5.50336860e-03,  -2.48168183e-02,\n",
       "         -1.63756198e-04,   0.00000000e+00,  -1.70254220e-05,\n",
       "          1.29876855e-05,  -5.14364795e-03,   6.69281453e-04],\n",
       "       [  0.00000000e+00,  -3.87821276e-03,  -4.51868214e-03,\n",
       "         -2.26610387e-03,   7.19763456e-04,   0.00000000e+00,\n",
       "          0.00000000e+00,  -5.10236549e-02,   0.00000000e+00,\n",
       "         -3.47633726e-03,   1.30705004e-03,  -1.45830788e-02,\n",
       "         -1.91048898e-04,   6.65082271e-02,   4.23090220e-05,\n",
       "          6.16364736e-06,  -2.89330197e-03,   1.47606982e-03],\n",
       "       [  0.00000000e+00,  -7.75642553e-03,  -1.20498190e-02,\n",
       "         -1.30002801e-02,   1.60518166e-03,  -8.52950206e-03,\n",
       "          0.00000000e+00,  -5.10236549e-02,   0.00000000e+00,\n",
       "         -5.21450589e-03,  -8.32384500e-03,  -2.48168183e-02,\n",
       "         -3.13866046e-04,   0.00000000e+00,   4.70885840e-05,\n",
       "          1.56292487e-05,   3.72914476e-03,   1.64764925e-03]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(features_train[i]-features_test[0])\n",
    "\n",
    "features_train[0:3] - features_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform 1-nearest neighbor regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the element-wise differences, it is not too hard to compute the Euclidean distances between our query house and all of the training houses. First, write a single-line expression to define a variable diff such that `diff[i]` gives the element-wise difference between the features of the query house and the i-th training house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diff = features_train - features_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step in computing the Euclidean distances is to take these feature-by-feature differences in diff, square each, and take the sum over feature indices. That is, compute the sum of square feature differences for each training house (row in diff).\n",
    "\n",
    "By default, np.sum sums up everything in the matrix and returns a single number. To instead sum only over a row or column, we need to specifiy the axis parameter described in the np.sum documentation. In particular, axis=1 computes the sum across each row.\n",
    "\n",
    "Below, we compute this sum of square feature differences for all training houses and verify that the output for the 16th house in the training set is equivalent to having examined only the 16th row of diff and computing the sum of squares on that row alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance from 15th house in Train set:  0.0237082324167\n"
     ]
    }
   ],
   "source": [
    "distances = np.sqrt(np.sum(diff**2, axis=1))\n",
    "print(\"Distance from 15th house in Train set: \", distances[100]) # Euclidean distance between the query house and the 101th training house"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are ready to write a function that computes the distances from a query house to all training houses. The function should take two parameters: (i) the matrix of training features and (ii) the single feature vector associated with the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_distances(train_matrix, query_vector):\n",
    "    diff = train_matrix - query_vector\n",
    "    distances = np.sqrt(np.sum(diff**2, axis=1))\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance form 3rd House: \n",
      "Closest Distance:  0.00286049555751\n",
      "Closest House ID:  [ 382 1149 4087 ..., 1107 5226 2486]\n",
      "Closest Price:  249000.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Distance form 3rd House: \")\n",
    "third_house_distance = compute_distances(features_train, features_test[2])\n",
    "print(\"Closest Distance: \", third_house_distance[382])\n",
    "print(\"Closest House ID: \", np.argsort(third_house_distance, axis = 0))\n",
    "print(\"Closest Price: \", output_train[382])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform k-nearest neighbor regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For k-nearest neighbors, we need to find a set of k houses in the training set closest to a given query house. We then make predictions based on these k nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch k-nearest neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the functions above, implement a function that takes in\n",
    "* the value of k;\n",
    "* the feature matrix for the training houses; and\n",
    "* the feature vector of the query house\n",
    "\n",
    "and returns the indices of the k closest training houses. For instance, with 2-nearest neighbor, a return value of [5, 10] would indicate that the 6th and 11th training houses are closest to the query house.\n",
    "\n",
    "Hint: Look at the documentation for np.argsort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def k_nearest_neighbors(k, feature_train, features_query):\n",
    "    distances = compute_distances(feature_train, features_query)\n",
    "    neighbors = np.argsort(distances,axis=0)[:k]\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a single prediction by averaging k nearest neighbor outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know how to find the k-nearest neighbors, write a function that predicts the value of a given query house. **For simplicity, take the average of the prices of the k nearest neighbors in the training set.** The function should have the following parameters:\n",
    "\n",
    "* the value of k;\n",
    "* the feature matrix for the training houses;\n",
    "* the output values (prices) of the training houses; and\n",
    "* the feature vector of the query house, whose price we are predicting.\n",
    "\n",
    "The function should return a predicted value of the query house.\n",
    "\n",
    "**Hint**: You can extract multiple items from a Numpy array using a list of indices. For instance, `output_train[[6, 10]]` returns the prices of the 7th and 11th training houses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_output_of_query(k, features_train, output_train, features_query):\n",
    "    k_neighbors = k_nearest_neighbors(k,features_train,features_query)\n",
    "    prediction = np.mean(output_train[k_neighbors])\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make multiple predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function to predict the value of each and every house in a query set. (The query set can be any subset of the dataset, be it the test set or validation set.) The idea is to have a loop where we take each house in the query set as the query house and make a prediction for that specific house. The new function should take the following parameters:\n",
    "\n",
    "* the value of k;\n",
    "* the feature matrix for the training houses;\n",
    "* the output values (prices) of the training houses; and\n",
    "* the feature matrix for the query set.\n",
    "* The function should return a set of predicted values, one for each house in the query set.\n",
    "\n",
    "**Hint**: To get the number of houses in the query set, use the .shape field of the query features matrix. See the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(features_test[0:10].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_output(k, features_train, output_train, features_query):\n",
    "    nrow = features_query.shape[0]\n",
    "    predictions = []\n",
    "    for i in range(nrow):\n",
    "        prediction = predict_output_of_query(k,features_train, output_train, features_query[i])\n",
    "        predictions.append(prediction)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the best value of k using a validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There remains a question of choosing the value of k to use in making predictions. Here, we use a validation set to choose this value. Write a loop that does the following:\n",
    "\n",
    "* For k in [1, 2, ..., 15]:\n",
    "* Makes predictions for each house in the VALIDATION set using the k-nearest neighbors from the TRAINING set.\n",
    "* Computes the RSS for these predictions on the VALIDATION set\n",
    "* Stores the RSS computed above in rss_all\n",
    "* Report which k produced the lowest RSS on VALIDATION set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Choosing the best value of k using a validation set\n",
    "rss_all = {}\n",
    "for k in range(1,16):    \n",
    "    predict_value = predict_output(k, features_train, output_train, features_valid)\n",
    "    residual = (output_valid - predict_value)\n",
    "    rss = sum(residual**2)\n",
    "    rss_all[k] = rss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To visualize the performance as a function of k, plot the RSS on the VALIDATION set for each considered k value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best K:  8\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEDCAYAAAAyZm/jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHPxmZjnj4Dczy5n/D4NbN7tgWnbJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2187614b048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_k = min(rss_all.items(), key = lambda x: x[1])[0]\n",
    "print(\"Best K: \", best_k)\n",
    "# To visualize the performance as a function of k, plot the RSS on the VALIDATION set for each considered k value:\n",
    "plt.plot(list(rss_all.keys()), list(rss_all.values()),'bo-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply this k on TEST data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS on Test Set:  1.33118823552e+14\n"
     ]
    }
   ],
   "source": [
    "predict_value_test = predict_output(best_k, features_train, output_train, features_test)\n",
    "residual = (output_test - predict_value_test)\n",
    "RSS = sum(residual**2)\n",
    "print(\"RSS on Test Set: \", RSS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
