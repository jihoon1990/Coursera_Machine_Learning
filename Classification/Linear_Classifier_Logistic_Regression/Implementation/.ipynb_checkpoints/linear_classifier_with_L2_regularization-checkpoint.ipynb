{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Classifier with L2 Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data & Train-Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = pd.read_csv('amazon_baby_subset.csv')\n",
    "# Fill N/A\n",
    "products = products.fillna({'review':''})  # fill in N/A's in the review column\n",
    "# Reomove Punctuation for Text Cleaning\n",
    "products['review'] = products['review'].astype('str')\n",
    "products['review_clean'] = products['review'].apply(lambda x: ''.join([i for i in x if i not in string.punctuation]))\n",
    "# Add Sentiment Column\n",
    "products['sentiment'] = products['rating'].apply(lambda rating: 1 if rating >= 4 else -1)\n",
    "\n",
    "# Import Important words\n",
    "important_words = pd.read_json('important_words.json')\n",
    "\n",
    "# Counting Important words in `review_clean` column\n",
    "for word in important_words[0].values.tolist():\n",
    "    products[word] = products['review_clean'].apply(lambda s : s.split().count(word))\n",
    "\n",
    "# Extract Train Data\n",
    "train_index = pd.read_json('train-idx.json')\n",
    "train_idx_list = train_index[0].values.tolist()\n",
    "train_data = products.ix[train_idx_list]\n",
    "# Extract Test Data\n",
    "valid_index = pd.read_json('validation-idx.json')\n",
    "valid_idx_list = valid_index[0].values.tolist()\n",
    "valid_data = products.ix[valid_idx_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>baby</th>\n",
       "      <th>one</th>\n",
       "      <th>great</th>\n",
       "      <th>love</th>\n",
       "      <th>use</th>\n",
       "      <th>...</th>\n",
       "      <th>seems</th>\n",
       "      <th>picture</th>\n",
       "      <th>completely</th>\n",
       "      <th>wish</th>\n",
       "      <th>buying</th>\n",
       "      <th>babies</th>\n",
       "      <th>won</th>\n",
       "      <th>tub</th>\n",
       "      <th>almost</th>\n",
       "      <th>either</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>All of my kids have cried nonstop when I tried...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lamaze Peekaboo, I Love You</td>\n",
       "      <td>One of baby's first and favorite books, and it...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>One of babys first and favorite books and it i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SoftPlay Peek-A-Boo Where's Elmo A Children's ...</td>\n",
       "      <td>Very cute interactive book! My son loves this ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Very cute interactive book My son loves this b...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Our Baby Girl Memory Book</td>\n",
       "      <td>Beautiful book, I love it to record cherished ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Beautiful book I love it to record cherished t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Stop Pacifier Sucking without tears with Thumb...   \n",
       "1    Nature's Lullabies Second Year Sticker Calendar   \n",
       "3                        Lamaze Peekaboo, I Love You   \n",
       "4  SoftPlay Peek-A-Boo Where's Elmo A Children's ...   \n",
       "5                          Our Baby Girl Memory Book   \n",
       "\n",
       "                                              review  rating  sentiment  \\\n",
       "0  All of my kids have cried non-stop when I trie...       5          1   \n",
       "1  We wanted to get something to keep track of ou...       5          1   \n",
       "3  One of baby's first and favorite books, and it...       4          1   \n",
       "4  Very cute interactive book! My son loves this ...       5          1   \n",
       "5  Beautiful book, I love it to record cherished ...       5          1   \n",
       "\n",
       "                                        review_clean  baby  one  great  love  \\\n",
       "0  All of my kids have cried nonstop when I tried...     0    0      1     0   \n",
       "1  We wanted to get something to keep track of ou...     0    0      0     0   \n",
       "3  One of babys first and favorite books and it i...     0    0      0     0   \n",
       "4  Very cute interactive book My son loves this b...     0    0      1     0   \n",
       "5  Beautiful book I love it to record cherished t...     0    0      1     1   \n",
       "\n",
       "   use   ...    seems  picture  completely  wish  buying  babies  won  tub  \\\n",
       "0    0   ...        0        0           0     0       0       0    0    0   \n",
       "1    0   ...        0        0           0     0       0       0    0    0   \n",
       "3    0   ...        0        0           0     0       0       0    0    0   \n",
       "4    0   ...        0        0           0     0       0       1    0    0   \n",
       "5    0   ...        0        0           0     0       0       0    0    0   \n",
       "\n",
       "   almost  either  \n",
       "0       0       0  \n",
       "1       0       0  \n",
       "3       0       0  \n",
       "4       0       0  \n",
       "5       0       0  \n",
       "\n",
       "[5 rows x 198 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>baby</th>\n",
       "      <th>one</th>\n",
       "      <th>great</th>\n",
       "      <th>love</th>\n",
       "      <th>use</th>\n",
       "      <th>...</th>\n",
       "      <th>seems</th>\n",
       "      <th>picture</th>\n",
       "      <th>completely</th>\n",
       "      <th>wish</th>\n",
       "      <th>buying</th>\n",
       "      <th>babies</th>\n",
       "      <th>won</th>\n",
       "      <th>tub</th>\n",
       "      <th>almost</th>\n",
       "      <th>either</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>My daughter had her 1st baby over a year ago. ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>My daughter had her 1st baby over a year ago S...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cloth Diaper Pins Stainless Steel Traditional ...</td>\n",
       "      <td>It has been many years since we needed diaper ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>It has been many years since we needed diaper ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Fisher Price Nesting Action Vehicles</td>\n",
       "      <td>For well over a year my son has enjoyed stacki...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>For well over a year my son has enjoyed stacki...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Sassy Who Loves Baby? Photo Album Book with te...</td>\n",
       "      <td>I bought this for a new granddaughter.  I will...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>I bought this for a new granddaughter  I will ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Earlyears: Earl E. Bird with Teething Rings</td>\n",
       "      <td>We received an Earl E. Bird as a gift when we ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>We received an Earl E Bird as a gift when we h...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name  \\\n",
       "2     Nature's Lullabies Second Year Sticker Calendar   \n",
       "9   Cloth Diaper Pins Stainless Steel Traditional ...   \n",
       "23               Fisher Price Nesting Action Vehicles   \n",
       "26  Sassy Who Loves Baby? Photo Album Book with te...   \n",
       "27        Earlyears: Earl E. Bird with Teething Rings   \n",
       "\n",
       "                                               review  rating  sentiment  \\\n",
       "2   My daughter had her 1st baby over a year ago. ...       5          1   \n",
       "9   It has been many years since we needed diaper ...       5          1   \n",
       "23  For well over a year my son has enjoyed stacki...       5          1   \n",
       "26  I bought this for a new granddaughter.  I will...       5          1   \n",
       "27  We received an Earl E. Bird as a gift when we ...       5          1   \n",
       "\n",
       "                                         review_clean  baby  one  great  love  \\\n",
       "2   My daughter had her 1st baby over a year ago S...     1    0      0     0   \n",
       "9   It has been many years since we needed diaper ...     0    1      0     0   \n",
       "23  For well over a year my son has enjoyed stacki...     0    1      0     0   \n",
       "26  I bought this for a new granddaughter  I will ...     0    0      2     0   \n",
       "27  We received an Earl E Bird as a gift when we h...     4    0      1     0   \n",
       "\n",
       "    use   ...    seems  picture  completely  wish  buying  babies  won  tub  \\\n",
       "2     0   ...        0        0           0     0       0       0    0    0   \n",
       "9     0   ...        0        0           0     0       0       0    0    0   \n",
       "23    0   ...        0        0           0     0       0       0    0    0   \n",
       "26    0   ...        0        0           0     0       0       0    0    0   \n",
       "27    0   ...        0        0           0     0       0       0    0    0   \n",
       "\n",
       "    almost  either  \n",
       "2        0       0  \n",
       "9        0       0  \n",
       "23       0       0  \n",
       "26       0       0  \n",
       "27       0       0  \n",
       "\n",
       "[5 rows x 198 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Train Data:  42361\n",
      "Number of Validation Data:  10711\n"
     ]
    }
   ],
   "source": [
    "# Train-Validation Split\n",
    "print(\"Number of Train Data: \", len(train_data))\n",
    "print(\"Number of Validation Data: \", len(valid_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to Numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of feature matrix:  (42361, 194)\n",
      "Size of feature matrix:  (10711, 194)\n"
     ]
    }
   ],
   "source": [
    "feature_set = ['intercept'] + important_words[0].tolist()\n",
    "## Train Data\n",
    "train_data['intercept'] = 1\n",
    "feature_matrix_train = train_data[feature_set].as_matrix()\n",
    "sentiment_train = train_data['sentiment'].as_matrix()\n",
    "# Shape of feature matrix\n",
    "print(\"Size of feature matrix: \", feature_matrix_train.shape)\n",
    "\n",
    "## Validation Data\n",
    "valid_data['intercept'] = 1\n",
    "feature_matrix_valid = valid_data[feature_set].as_matrix()\n",
    "sentiment_valid = valid_data['sentiment'].as_matrix()\n",
    "# Shape of feature matrix\n",
    "print(\"Size of feature matrix: \", feature_matrix_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building on logistic regression with no L2 penalty assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the link function for logistic regression can be defined as:\n",
    "$$\n",
    "P(y_i = +1 | \\mathbf{x}_i,\\mathbf{w}) = \\frac{1}{1 + \\exp(-\\mathbf{w}^T h(\\mathbf{x}_i))},\n",
    "$$\n",
    "where the feature vector $h(\\mathbf{x}_i)$ is given by the word counts of important_words in the review $\\mathbf{x}_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_probability(feature_matrix, coefficients):\n",
    "    # Take dot product of feature_matrix and coefficients  \n",
    "    # YOUR CODE HERE\n",
    "    scores = np.dot(feature_matrix, coefficients)\n",
    "    \n",
    "    # Compute P(y_i = +1 | x_i, w) using the link function\n",
    "    # YOUR CODE HERE\n",
    "    predictions = 1. / (1 + np.exp(-scores))\n",
    "    \n",
    "    # return predictions\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding L2 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now work on extending logistic regression with L2 regularization. As discussed in the lectures, the L2 regularization is particularly useful in preventing overfitting. In this assignment, we will explore L2 regularization in detail.\n",
    "\n",
    "Recall from lecture and the previous assignment that for logistic regression without an L2 penalty, the derivative of the log likelihood function is: $$\n",
    "\\frac{\\partial\\ell}{\\partial w_j} = \\sum_{i=1}^N h_j(\\mathbf{x}_i)\\left(\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w})\\right)\n",
    "$$\n",
    "\n",
    "**Adding L2 penalty to the derivative**\n",
    "\n",
    "It takes only a small modification to add a L2 penalty. All terms indicated in red refer to terms that were added due to an L2 penalty.\n",
    "\n",
    "* Recall from the lecture that the link function is still the sigmoid: $$\n",
    "P(y_i = +1 | \\mathbf{x}_i,\\mathbf{w}) = \\frac{1}{1 + \\exp(-\\mathbf{w}^T h(\\mathbf{x}_i))},\n",
    "$$\n",
    "\n",
    "* We add the L2 penalty term to the per-coefficient derivative of log likelihood: $$\n",
    "\\frac{\\partial\\ell}{\\partial w_j} = \\sum_{i=1}^N h_j(\\mathbf{x}_i)\\left(\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w})\\right) \\color{red}{-2\\lambda w_j }\n",
    "$$\n",
    "\n",
    "The **per-coefficient derivative for logistic regression with an L2 penalty **is as follows: $$\n",
    "\\frac{\\partial\\ell}{\\partial w_j} = \\sum_{i=1}^N h_j(\\mathbf{x}_i)\\left(\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w})\\right) \\color{red}{-2\\lambda w_j }\n",
    "$$ and for the intercept term, we have $$\n",
    "\\frac{\\partial\\ell}{\\partial w_0} = \\sum_{i=1}^N h_0(\\mathbf{x}_i)\\left(\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w})\\right)\n",
    "$$\n",
    "\n",
    "Note: As we did in the Regression course, we do not apply the L2 penalty on the intercept. A large intercept does not necessarily indicate overfitting because the intercept is not associated with any particular feature.\n",
    "\n",
    "Write a function that computes the derivative of log likelihood with respect to a single coefficient $w_j$. Unlike its counterpart in the last assignment, the function accepts five arguments:\n",
    "\n",
    "* `errors` vector containing $(\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w}))$ for all $i$\n",
    "* `feature` vector containing $h_j(\\mathbf{x}_i)$ for all $i$\n",
    "* `coefficient` containing the current value of coefficient $w_j$.\n",
    "* `l2_penalty` representing the L2 penalty constant $\\lambda$\n",
    "* `feature_is_constant` telling whether the $j$-th feature is constant or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_derivative_with_L2(errors, feature, coefficient, l2_penalty, feature_is_constant): \n",
    "    \n",
    "    # Compute the dot product of errors and feature\n",
    "    ## YOUR CODE HERE\n",
    "    derivative = np.dot(errors, feature)\n",
    "\n",
    "    # add L2 penalty term for any feature that isn't the intercept.\n",
    "    if not feature_is_constant: \n",
    "        ## YOUR CODE HERE\n",
    "        derivative -= (2 * l2_penalty * coefficient)\n",
    "        \n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify the correctness of the gradient ascent algorithm, we provide a function for computing log likelihood (which we recall from the last assignment was a topic detailed in an advanced optional video, and used here for its numerical stability).\n",
    "$$\\ell\\ell(\\mathbf{w}) = \\sum_{i=1}^N \\Big( (\\mathbf{1}[y_i = +1] - 1)\\mathbf{w}^T h(\\mathbf{x}_i) - \\ln\\left(1 + \\exp(-\\mathbf{w}^T h(\\mathbf{x}_i))\\right) \\Big) \\color{red}{-\\lambda\\|\\mathbf{w}\\|_2^2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_log_likelihood_with_L2(feature_matrix, sentiment, coefficients, l2_penalty):\n",
    "    indicator = (sentiment==+1)\n",
    "    scores = np.dot(feature_matrix, coefficients)\n",
    "    \n",
    "    lp = np.sum((indicator-1)*scores - np.log(1. + np.exp(-scores))) - l2_penalty*np.sum(coefficients[1:]**2)\n",
    "    \n",
    "    return lp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression function looks almost like the one in the last assignment, with a minor modification to account for the L2 penalty. Fill in the code below to complete this modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_regression_with_L2(feature_matrix, sentiment, initial_coefficients, step_size, l2_penalty, max_iter):\n",
    "    coefficients = np.array(initial_coefficients) # make sure it's a numpy array\n",
    "    for itr in range(max_iter):\n",
    "        # Predict P(y_i = +1|x_i,w) using your predict_probability() function\n",
    "        ## YOUR CODE HERE\n",
    "        predictions = predict_probability(feature_matrix, coefficients)\n",
    "        \n",
    "        # Compute indicator value for (y_i = +1)\n",
    "        indicator = (sentiment==+1)\n",
    "        \n",
    "        # Compute the errors as indicator - predictions\n",
    "        errors = indicator - predictions\n",
    "        \n",
    "        for j in range(len(coefficients)): # loop over each coefficient\n",
    "            is_intercept = (j == 0)\n",
    "            # Recall that feature_matrix[:,j] is the feature column associated with coefficients[j].\n",
    "            # Compute the derivative for coefficients[j]. Save it in a variable called derivative\n",
    "            ## YOUR CODE HERE\n",
    "            derivative = feature_derivative_with_L2(errors, feature_matrix[:,j], coefficients[j], l2_penalty, is_intercept)\n",
    "            \n",
    "            # add the step size times the derivative to the current coefficient\n",
    "            ## YOUR CODE HERE\n",
    "            coefficients[j] += step_size * derivative\n",
    "        \n",
    "        # Checking whether log likelihood is increasing\n",
    "        if itr <= 15 or (itr <= 100 and itr % 10 == 0) or (itr <= 1000 and itr % 100 == 0) \\\n",
    "        or (itr <= 10000 and itr % 1000 == 0) or itr % 10000 == 0:\n",
    "            lp = compute_log_likelihood_with_L2(feature_matrix, sentiment, coefficients, l2_penalty)\n",
    "            print('iteration %*d: log likelihood of observed labels = %.8f' % \\\n",
    "                (int(np.ceil(np.log10(max_iter))), itr, lp))\n",
    "    return coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore effects of L2 regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have written up all the pieces needed for regularized logistic regression, let's explore the benefits of using **L2 regularization** in analyzing sentiment for product reviews. **As iterations pass, the log likelihood should increase.**\n",
    "\n",
    "Below, we train models with increasing amounts of regularization, starting with no L2 penalty, which is equivalent to our previous logistic regression implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -29179.39138303\n",
      "iteration   1: log likelihood of observed labels = -29003.71259047\n",
      "iteration   2: log likelihood of observed labels = -28834.66187288\n",
      "iteration   3: log likelihood of observed labels = -28671.70781507\n",
      "iteration   4: log likelihood of observed labels = -28514.43078198\n",
      "iteration   5: log likelihood of observed labels = -28362.48344665\n",
      "iteration   6: log likelihood of observed labels = -28215.56713122\n",
      "iteration   7: log likelihood of observed labels = -28073.41743783\n",
      "iteration   8: log likelihood of observed labels = -27935.79536396\n",
      "iteration   9: log likelihood of observed labels = -27802.48168669\n",
      "iteration  10: log likelihood of observed labels = -27673.27331484\n",
      "iteration  11: log likelihood of observed labels = -27547.98083656\n",
      "iteration  12: log likelihood of observed labels = -27426.42679977\n",
      "iteration  13: log likelihood of observed labels = -27308.44444728\n",
      "iteration  14: log likelihood of observed labels = -27193.87673876\n",
      "iteration  15: log likelihood of observed labels = -27082.57555831\n",
      "iteration  20: log likelihood of observed labels = -26570.43059938\n",
      "iteration  30: log likelihood of observed labels = -25725.48742389\n",
      "iteration  40: log likelihood of observed labels = -25055.53326910\n",
      "iteration  50: log likelihood of observed labels = -24509.63590026\n",
      "iteration  60: log likelihood of observed labels = -24054.97906083\n",
      "iteration  70: log likelihood of observed labels = -23669.51640848\n",
      "iteration  80: log likelihood of observed labels = -23337.89167628\n",
      "iteration  90: log likelihood of observed labels = -23049.07066021\n",
      "iteration 100: log likelihood of observed labels = -22794.90974921\n",
      "iteration 200: log likelihood of observed labels = -21283.29527353\n",
      "iteration 300: log likelihood of observed labels = -20570.97485473\n",
      "iteration 400: log likelihood of observed labels = -20152.21466944\n",
      "iteration 500: log likelihood of observed labels = -19876.62333410\n"
     ]
    }
   ],
   "source": [
    "# run with L2 = 0\n",
    "coefficients_0_penalty = logistic_regression_with_L2(feature_matrix_train, sentiment_train,\n",
    "                                                     initial_coefficients=np.zeros(194),\n",
    "                                                     step_size=5e-6, l2_penalty=0, max_iter=501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -29179.39508175\n",
      "iteration   1: log likelihood of observed labels = -29003.73417180\n",
      "iteration   2: log likelihood of observed labels = -28834.71441858\n",
      "iteration   3: log likelihood of observed labels = -28671.80345068\n",
      "iteration   4: log likelihood of observed labels = -28514.58077957\n",
      "iteration   5: log likelihood of observed labels = -28362.69830317\n",
      "iteration   6: log likelihood of observed labels = -28215.85663259\n",
      "iteration   7: log likelihood of observed labels = -28073.79071393\n",
      "iteration   8: log likelihood of observed labels = -27936.26093762\n",
      "iteration   9: log likelihood of observed labels = -27803.04751805\n",
      "iteration  10: log likelihood of observed labels = -27673.94684207\n",
      "iteration  11: log likelihood of observed labels = -27548.76901327\n",
      "iteration  12: log likelihood of observed labels = -27427.33612958\n",
      "iteration  13: log likelihood of observed labels = -27309.48101569\n",
      "iteration  14: log likelihood of observed labels = -27195.04624253\n",
      "iteration  15: log likelihood of observed labels = -27083.88333261\n",
      "iteration  20: log likelihood of observed labels = -26572.49874392\n",
      "iteration  30: log likelihood of observed labels = -25729.32604153\n",
      "iteration  40: log likelihood of observed labels = -25061.34245801\n",
      "iteration  50: log likelihood of observed labels = -24517.52091982\n",
      "iteration  60: log likelihood of observed labels = -24064.99093939\n",
      "iteration  70: log likelihood of observed labels = -23681.67373669\n",
      "iteration  80: log likelihood of observed labels = -23352.19298741\n",
      "iteration  90: log likelihood of observed labels = -23065.50180166\n",
      "iteration 100: log likelihood of observed labels = -22813.44844580\n",
      "iteration 200: log likelihood of observed labels = -21321.14164794\n",
      "iteration 300: log likelihood of observed labels = -20624.98634439\n",
      "iteration 400: log likelihood of observed labels = -20219.92048845\n",
      "iteration 500: log likelihood of observed labels = -19956.11341777\n"
     ]
    }
   ],
   "source": [
    "# run with L2 = 4\n",
    "coefficients_4_penalty = logistic_regression_with_L2(feature_matrix_train, sentiment_train,\n",
    "                                                      initial_coefficients=np.zeros(194),\n",
    "                                                      step_size=5e-6, l2_penalty=4, max_iter=501)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -29179.40062984\n",
      "iteration   1: log likelihood of observed labels = -29003.76654163\n",
      "iteration   2: log likelihood of observed labels = -28834.79322654\n",
      "iteration   3: log likelihood of observed labels = -28671.94687528\n",
      "iteration   4: log likelihood of observed labels = -28514.80571589\n",
      "iteration   5: log likelihood of observed labels = -28363.02048079\n",
      "iteration   6: log likelihood of observed labels = -28216.29071186\n",
      "iteration   7: log likelihood of observed labels = -28074.35036891\n",
      "iteration   8: log likelihood of observed labels = -27936.95892966\n",
      "iteration   9: log likelihood of observed labels = -27803.89576265\n",
      "iteration  10: log likelihood of observed labels = -27674.95647005\n",
      "iteration  11: log likelihood of observed labels = -27549.95042714\n",
      "iteration  12: log likelihood of observed labels = -27428.69905549\n",
      "iteration  13: log likelihood of observed labels = -27311.03455140\n",
      "iteration  14: log likelihood of observed labels = -27196.79890162\n",
      "iteration  15: log likelihood of observed labels = -27085.84308528\n",
      "iteration  20: log likelihood of observed labels = -26575.59697506\n",
      "iteration  30: log likelihood of observed labels = -25735.07304608\n",
      "iteration  40: log likelihood of observed labels = -25070.03447306\n",
      "iteration  50: log likelihood of observed labels = -24529.31188025\n",
      "iteration  60: log likelihood of observed labels = -24079.95349572\n",
      "iteration  70: log likelihood of observed labels = -23699.83199186\n",
      "iteration  80: log likelihood of observed labels = -23373.54108747\n",
      "iteration  90: log likelihood of observed labels = -23090.01500055\n",
      "iteration 100: log likelihood of observed labels = -22841.08995135\n",
      "iteration 200: log likelihood of observed labels = -21377.25595328\n",
      "iteration 300: log likelihood of observed labels = -20704.63995428\n",
      "iteration 400: log likelihood of observed labels = -20319.25685307\n",
      "iteration 500: log likelihood of observed labels = -20072.16321721\n"
     ]
    }
   ],
   "source": [
    "# run with L2 = 10\n",
    "coefficients_10_penalty = logistic_regression_with_L2(feature_matrix_train, sentiment_train,\n",
    "                                                      initial_coefficients=np.zeros(194),\n",
    "                                                      step_size=5e-6, l2_penalty=10, max_iter=501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -29179.48385120\n",
      "iteration   1: log likelihood of observed labels = -29004.25177457\n",
      "iteration   2: log likelihood of observed labels = -28835.97382190\n",
      "iteration   3: log likelihood of observed labels = -28674.09410083\n",
      "iteration   4: log likelihood of observed labels = -28518.17112932\n",
      "iteration   5: log likelihood of observed labels = -28367.83774654\n",
      "iteration   6: log likelihood of observed labels = -28222.77708939\n",
      "iteration   7: log likelihood of observed labels = -28082.70799392\n",
      "iteration   8: log likelihood of observed labels = -27947.37595368\n",
      "iteration   9: log likelihood of observed labels = -27816.54738615\n",
      "iteration  10: log likelihood of observed labels = -27690.00588850\n",
      "iteration  11: log likelihood of observed labels = -27567.54970126\n",
      "iteration  12: log likelihood of observed labels = -27448.98991327\n",
      "iteration  13: log likelihood of observed labels = -27334.14912742\n",
      "iteration  14: log likelihood of observed labels = -27222.86041863\n",
      "iteration  15: log likelihood of observed labels = -27114.96648229\n",
      "iteration  20: log likelihood of observed labels = -26621.50201299\n",
      "iteration  30: log likelihood of observed labels = -25819.72803950\n",
      "iteration  40: log likelihood of observed labels = -25197.34035501\n",
      "iteration  50: log likelihood of observed labels = -24701.03698195\n",
      "iteration  60: log likelihood of observed labels = -24296.66378580\n",
      "iteration  70: log likelihood of observed labels = -23961.38842316\n",
      "iteration  80: log likelihood of observed labels = -23679.38088853\n",
      "iteration  90: log likelihood of observed labels = -23439.31824267\n",
      "iteration 100: log likelihood of observed labels = -23232.88192018\n",
      "iteration 200: log likelihood of observed labels = -22133.50726528\n",
      "iteration 300: log likelihood of observed labels = -21730.03957488\n",
      "iteration 400: log likelihood of observed labels = -21545.87572145\n",
      "iteration 500: log likelihood of observed labels = -21451.95551390\n"
     ]
    }
   ],
   "source": [
    "# run with L2 = 1e2\n",
    "coefficients_1e2_penalty = logistic_regression_with_L2(feature_matrix_train, sentiment_train,\n",
    "                                                       initial_coefficients=np.zeros(194),\n",
    "                                                       step_size=5e-6, l2_penalty=1e2, max_iter=501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -29180.31606471\n",
      "iteration   1: log likelihood of observed labels = -29009.07176112\n",
      "iteration   2: log likelihood of observed labels = -28847.62378912\n",
      "iteration   3: log likelihood of observed labels = -28695.14439397\n",
      "iteration   4: log likelihood of observed labels = -28550.95060743\n",
      "iteration   5: log likelihood of observed labels = -28414.45771129\n",
      "iteration   6: log likelihood of observed labels = -28285.15124375\n",
      "iteration   7: log likelihood of observed labels = -28162.56976044\n",
      "iteration   8: log likelihood of observed labels = -28046.29387744\n",
      "iteration   9: log likelihood of observed labels = -27935.93902900\n",
      "iteration  10: log likelihood of observed labels = -27831.15045502\n",
      "iteration  11: log likelihood of observed labels = -27731.59955260\n",
      "iteration  12: log likelihood of observed labels = -27636.98108219\n",
      "iteration  13: log likelihood of observed labels = -27547.01092670\n",
      "iteration  14: log likelihood of observed labels = -27461.42422295\n",
      "iteration  15: log likelihood of observed labels = -27379.97375625\n",
      "iteration  20: log likelihood of observed labels = -27027.18208317\n",
      "iteration  30: log likelihood of observed labels = -26527.22737267\n",
      "iteration  40: log likelihood of observed labels = -26206.59048765\n",
      "iteration  50: log likelihood of observed labels = -25995.96903148\n",
      "iteration  60: log likelihood of observed labels = -25854.95710284\n",
      "iteration  70: log likelihood of observed labels = -25759.08109950\n",
      "iteration  80: log likelihood of observed labels = -25693.05688014\n",
      "iteration  90: log likelihood of observed labels = -25647.09929349\n",
      "iteration 100: log likelihood of observed labels = -25614.81468705\n",
      "iteration 200: log likelihood of observed labels = -25536.20998919\n",
      "iteration 300: log likelihood of observed labels = -25532.57691220\n",
      "iteration 400: log likelihood of observed labels = -25532.35543765\n",
      "iteration 500: log likelihood of observed labels = -25532.33970049\n"
     ]
    }
   ],
   "source": [
    "# run with L2 = 1e3\n",
    "coefficients_1e3_penalty = logistic_regression_with_L2(feature_matrix_train, sentiment_train,\n",
    "                                                       initial_coefficients=np.zeros(194),\n",
    "                                                       step_size=5e-6, l2_penalty=1e3, max_iter=501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -29271.85955115\n",
      "iteration   1: log likelihood of observed labels = -29271.71006589\n",
      "iteration   2: log likelihood of observed labels = -29271.65738833\n",
      "iteration   3: log likelihood of observed labels = -29271.61189923\n",
      "iteration   4: log likelihood of observed labels = -29271.57079975\n",
      "iteration   5: log likelihood of observed labels = -29271.53358505\n",
      "iteration   6: log likelihood of observed labels = -29271.49988440\n",
      "iteration   7: log likelihood of observed labels = -29271.46936584\n",
      "iteration   8: log likelihood of observed labels = -29271.44172890\n",
      "iteration   9: log likelihood of observed labels = -29271.41670149\n",
      "iteration  10: log likelihood of observed labels = -29271.39403722\n",
      "iteration  11: log likelihood of observed labels = -29271.37351294\n",
      "iteration  12: log likelihood of observed labels = -29271.35492661\n",
      "iteration  13: log likelihood of observed labels = -29271.33809523\n",
      "iteration  14: log likelihood of observed labels = -29271.32285309\n",
      "iteration  15: log likelihood of observed labels = -29271.30905015\n",
      "iteration  20: log likelihood of observed labels = -29271.25729150\n",
      "iteration  30: log likelihood of observed labels = -29271.20657205\n",
      "iteration  40: log likelihood of observed labels = -29271.18775997\n",
      "iteration  50: log likelihood of observed labels = -29271.18078247\n",
      "iteration  60: log likelihood of observed labels = -29271.17819447\n",
      "iteration  70: log likelihood of observed labels = -29271.17723457\n",
      "iteration  80: log likelihood of observed labels = -29271.17687853\n",
      "iteration  90: log likelihood of observed labels = -29271.17674648\n",
      "iteration 100: log likelihood of observed labels = -29271.17669750\n",
      "iteration 200: log likelihood of observed labels = -29271.17666862\n",
      "iteration 300: log likelihood of observed labels = -29271.17666862\n",
      "iteration 400: log likelihood of observed labels = -29271.17666862\n",
      "iteration 500: log likelihood of observed labels = -29271.17666862\n"
     ]
    }
   ],
   "source": [
    "# run with L2 = 1e5\n",
    "coefficients_1e5_penalty = logistic_regression_with_L2(feature_matrix_train, sentiment_train,\n",
    "                                                       initial_coefficients=np.zeros(194),\n",
    "                                                       step_size=5e-6, l2_penalty=1e5, max_iter=501)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compare the coefficients for each of the models that were trained above. We will create a table of features and learned coefficients associated with each of the different L2 penalty values.\n",
    "\n",
    "Below is a simple helper function that will help us create this table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compare coefficients\n",
    "table = pd.DataFrame(feature_set)\n",
    "table = table.rename(columns={0:'words'})\n",
    "def add_coefficients_to_table(coefficients, column_name):\n",
    "    table[column_name] = coefficients\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's run the function `add_coefficients_to_table` for each of the L2 penalty strengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>coefficients [L2=0]</th>\n",
       "      <th>coefficients [L2=4]</th>\n",
       "      <th>coefficients [L2=10]</th>\n",
       "      <th>coefficients [L2=1e2]</th>\n",
       "      <th>coefficients [L2=1e3]</th>\n",
       "      <th>coefficients [L2=1e5]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>intercept</td>\n",
       "      <td>-0.063742</td>\n",
       "      <td>-0.063143</td>\n",
       "      <td>-0.062256</td>\n",
       "      <td>-0.050438</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.011362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baby</td>\n",
       "      <td>0.074073</td>\n",
       "      <td>0.073994</td>\n",
       "      <td>0.073877</td>\n",
       "      <td>0.072360</td>\n",
       "      <td>0.059752</td>\n",
       "      <td>0.001784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>one</td>\n",
       "      <td>0.012753</td>\n",
       "      <td>0.012495</td>\n",
       "      <td>0.012115</td>\n",
       "      <td>0.007247</td>\n",
       "      <td>-0.008761</td>\n",
       "      <td>-0.001827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>great</td>\n",
       "      <td>0.801625</td>\n",
       "      <td>0.796897</td>\n",
       "      <td>0.789935</td>\n",
       "      <td>0.701425</td>\n",
       "      <td>0.376012</td>\n",
       "      <td>0.008950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>love</td>\n",
       "      <td>1.058554</td>\n",
       "      <td>1.050856</td>\n",
       "      <td>1.039529</td>\n",
       "      <td>0.896644</td>\n",
       "      <td>0.418354</td>\n",
       "      <td>0.009042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>use</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.017326</td>\n",
       "      <td>0.000418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>would</td>\n",
       "      <td>-0.287021</td>\n",
       "      <td>-0.286027</td>\n",
       "      <td>-0.284564</td>\n",
       "      <td>-0.265993</td>\n",
       "      <td>-0.188662</td>\n",
       "      <td>-0.008127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>like</td>\n",
       "      <td>-0.003384</td>\n",
       "      <td>-0.003442</td>\n",
       "      <td>-0.003527</td>\n",
       "      <td>-0.004635</td>\n",
       "      <td>-0.007043</td>\n",
       "      <td>-0.000827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>easy</td>\n",
       "      <td>0.984559</td>\n",
       "      <td>0.977600</td>\n",
       "      <td>0.967362</td>\n",
       "      <td>0.838245</td>\n",
       "      <td>0.401904</td>\n",
       "      <td>0.008808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>little</td>\n",
       "      <td>0.524419</td>\n",
       "      <td>0.521385</td>\n",
       "      <td>0.516917</td>\n",
       "      <td>0.460235</td>\n",
       "      <td>0.251221</td>\n",
       "      <td>0.005941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>seat</td>\n",
       "      <td>-0.086968</td>\n",
       "      <td>-0.086125</td>\n",
       "      <td>-0.084883</td>\n",
       "      <td>-0.069109</td>\n",
       "      <td>-0.017718</td>\n",
       "      <td>0.000611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>old</td>\n",
       "      <td>0.208912</td>\n",
       "      <td>0.207749</td>\n",
       "      <td>0.206037</td>\n",
       "      <td>0.184332</td>\n",
       "      <td>0.105074</td>\n",
       "      <td>0.002741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>well</td>\n",
       "      <td>0.453866</td>\n",
       "      <td>0.450969</td>\n",
       "      <td>0.446700</td>\n",
       "      <td>0.392304</td>\n",
       "      <td>0.194926</td>\n",
       "      <td>0.003945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>get</td>\n",
       "      <td>-0.196835</td>\n",
       "      <td>-0.196100</td>\n",
       "      <td>-0.195017</td>\n",
       "      <td>-0.181251</td>\n",
       "      <td>-0.122728</td>\n",
       "      <td>-0.004578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>also</td>\n",
       "      <td>0.158163</td>\n",
       "      <td>0.157246</td>\n",
       "      <td>0.155899</td>\n",
       "      <td>0.139153</td>\n",
       "      <td>0.080918</td>\n",
       "      <td>0.001929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>really</td>\n",
       "      <td>-0.017906</td>\n",
       "      <td>-0.017745</td>\n",
       "      <td>-0.017508</td>\n",
       "      <td>-0.014481</td>\n",
       "      <td>-0.004448</td>\n",
       "      <td>-0.000340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>son</td>\n",
       "      <td>0.128396</td>\n",
       "      <td>0.127761</td>\n",
       "      <td>0.126828</td>\n",
       "      <td>0.115192</td>\n",
       "      <td>0.070411</td>\n",
       "      <td>0.001552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>time</td>\n",
       "      <td>-0.072429</td>\n",
       "      <td>-0.072281</td>\n",
       "      <td>-0.072065</td>\n",
       "      <td>-0.069480</td>\n",
       "      <td>-0.057581</td>\n",
       "      <td>-0.002805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bought</td>\n",
       "      <td>-0.151817</td>\n",
       "      <td>-0.150917</td>\n",
       "      <td>-0.149594</td>\n",
       "      <td>-0.132884</td>\n",
       "      <td>-0.072431</td>\n",
       "      <td>-0.001985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>product</td>\n",
       "      <td>-0.263330</td>\n",
       "      <td>-0.262328</td>\n",
       "      <td>-0.260854</td>\n",
       "      <td>-0.242391</td>\n",
       "      <td>-0.167962</td>\n",
       "      <td>-0.006211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>good</td>\n",
       "      <td>0.156507</td>\n",
       "      <td>0.155270</td>\n",
       "      <td>0.153445</td>\n",
       "      <td>0.129972</td>\n",
       "      <td>0.047879</td>\n",
       "      <td>0.000266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>daughter</td>\n",
       "      <td>0.263418</td>\n",
       "      <td>0.261775</td>\n",
       "      <td>0.259357</td>\n",
       "      <td>0.228685</td>\n",
       "      <td>0.117158</td>\n",
       "      <td>0.002401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>much</td>\n",
       "      <td>-0.013247</td>\n",
       "      <td>-0.013295</td>\n",
       "      <td>-0.013366</td>\n",
       "      <td>-0.014326</td>\n",
       "      <td>-0.015219</td>\n",
       "      <td>-0.000839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>loves</td>\n",
       "      <td>1.052484</td>\n",
       "      <td>1.043903</td>\n",
       "      <td>1.031265</td>\n",
       "      <td>0.870794</td>\n",
       "      <td>0.345870</td>\n",
       "      <td>0.006150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>stroller</td>\n",
       "      <td>-0.037533</td>\n",
       "      <td>-0.036988</td>\n",
       "      <td>-0.036186</td>\n",
       "      <td>-0.025990</td>\n",
       "      <td>0.005912</td>\n",
       "      <td>0.001326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>put</td>\n",
       "      <td>-0.000330</td>\n",
       "      <td>-0.000323</td>\n",
       "      <td>-0.000312</td>\n",
       "      <td>-0.000127</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>-0.000097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>months</td>\n",
       "      <td>-0.067995</td>\n",
       "      <td>-0.067315</td>\n",
       "      <td>-0.066314</td>\n",
       "      <td>-0.053594</td>\n",
       "      <td>-0.013083</td>\n",
       "      <td>-0.000157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>car</td>\n",
       "      <td>0.193364</td>\n",
       "      <td>0.191904</td>\n",
       "      <td>0.189754</td>\n",
       "      <td>0.162531</td>\n",
       "      <td>0.072719</td>\n",
       "      <td>0.001765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>still</td>\n",
       "      <td>0.188508</td>\n",
       "      <td>0.187071</td>\n",
       "      <td>0.184955</td>\n",
       "      <td>0.158163</td>\n",
       "      <td>0.068491</td>\n",
       "      <td>0.000976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>back</td>\n",
       "      <td>-0.268954</td>\n",
       "      <td>-0.267419</td>\n",
       "      <td>-0.265161</td>\n",
       "      <td>-0.236730</td>\n",
       "      <td>-0.134671</td>\n",
       "      <td>-0.003988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>started</td>\n",
       "      <td>-0.153174</td>\n",
       "      <td>-0.151852</td>\n",
       "      <td>-0.149905</td>\n",
       "      <td>-0.125084</td>\n",
       "      <td>-0.045084</td>\n",
       "      <td>-0.000877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>anything</td>\n",
       "      <td>-0.186801</td>\n",
       "      <td>-0.185242</td>\n",
       "      <td>-0.182943</td>\n",
       "      <td>-0.153602</td>\n",
       "      <td>-0.057284</td>\n",
       "      <td>-0.001053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>last</td>\n",
       "      <td>-0.099469</td>\n",
       "      <td>-0.098692</td>\n",
       "      <td>-0.097547</td>\n",
       "      <td>-0.083001</td>\n",
       "      <td>-0.034797</td>\n",
       "      <td>-0.000775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>company</td>\n",
       "      <td>-0.276548</td>\n",
       "      <td>-0.274151</td>\n",
       "      <td>-0.270621</td>\n",
       "      <td>-0.225839</td>\n",
       "      <td>-0.084898</td>\n",
       "      <td>-0.001719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>come</td>\n",
       "      <td>-0.032009</td>\n",
       "      <td>-0.031804</td>\n",
       "      <td>-0.031502</td>\n",
       "      <td>-0.027685</td>\n",
       "      <td>-0.014185</td>\n",
       "      <td>-0.000426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>returned</td>\n",
       "      <td>-0.572707</td>\n",
       "      <td>-0.567518</td>\n",
       "      <td>-0.559870</td>\n",
       "      <td>-0.462056</td>\n",
       "      <td>-0.150021</td>\n",
       "      <td>-0.002225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>maybe</td>\n",
       "      <td>-0.224076</td>\n",
       "      <td>-0.222015</td>\n",
       "      <td>-0.218976</td>\n",
       "      <td>-0.180192</td>\n",
       "      <td>-0.058149</td>\n",
       "      <td>-0.000945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>took</td>\n",
       "      <td>-0.046445</td>\n",
       "      <td>-0.046199</td>\n",
       "      <td>-0.045838</td>\n",
       "      <td>-0.041422</td>\n",
       "      <td>-0.025566</td>\n",
       "      <td>-0.000772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>broke</td>\n",
       "      <td>-0.555195</td>\n",
       "      <td>-0.550209</td>\n",
       "      <td>-0.542861</td>\n",
       "      <td>-0.448989</td>\n",
       "      <td>-0.148726</td>\n",
       "      <td>-0.002182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>makes</td>\n",
       "      <td>-0.009023</td>\n",
       "      <td>-0.008764</td>\n",
       "      <td>-0.008382</td>\n",
       "      <td>-0.003467</td>\n",
       "      <td>0.008757</td>\n",
       "      <td>0.000255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>stay</td>\n",
       "      <td>-0.300563</td>\n",
       "      <td>-0.297920</td>\n",
       "      <td>-0.294024</td>\n",
       "      <td>-0.244247</td>\n",
       "      <td>-0.083709</td>\n",
       "      <td>-0.001310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>instead</td>\n",
       "      <td>-0.193123</td>\n",
       "      <td>-0.191418</td>\n",
       "      <td>-0.188907</td>\n",
       "      <td>-0.156863</td>\n",
       "      <td>-0.054125</td>\n",
       "      <td>-0.000925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>idea</td>\n",
       "      <td>-0.465370</td>\n",
       "      <td>-0.461130</td>\n",
       "      <td>-0.454879</td>\n",
       "      <td>-0.374890</td>\n",
       "      <td>-0.118469</td>\n",
       "      <td>-0.001627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>head</td>\n",
       "      <td>-0.110472</td>\n",
       "      <td>-0.109559</td>\n",
       "      <td>-0.108215</td>\n",
       "      <td>-0.090992</td>\n",
       "      <td>-0.032986</td>\n",
       "      <td>-0.000502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>said</td>\n",
       "      <td>-0.098049</td>\n",
       "      <td>-0.097331</td>\n",
       "      <td>-0.096274</td>\n",
       "      <td>-0.082875</td>\n",
       "      <td>-0.037594</td>\n",
       "      <td>-0.000947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>less</td>\n",
       "      <td>-0.136801</td>\n",
       "      <td>-0.135652</td>\n",
       "      <td>-0.133958</td>\n",
       "      <td>-0.112360</td>\n",
       "      <td>-0.042260</td>\n",
       "      <td>-0.000873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>went</td>\n",
       "      <td>-0.106836</td>\n",
       "      <td>-0.106003</td>\n",
       "      <td>-0.104776</td>\n",
       "      <td>-0.089294</td>\n",
       "      <td>-0.039417</td>\n",
       "      <td>-0.001006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>working</td>\n",
       "      <td>-0.320363</td>\n",
       "      <td>-0.317559</td>\n",
       "      <td>-0.313427</td>\n",
       "      <td>-0.260764</td>\n",
       "      <td>-0.092334</td>\n",
       "      <td>-0.001674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>high</td>\n",
       "      <td>0.003326</td>\n",
       "      <td>0.003282</td>\n",
       "      <td>0.003217</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>-0.000062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>unit</td>\n",
       "      <td>-0.196121</td>\n",
       "      <td>-0.194516</td>\n",
       "      <td>-0.192153</td>\n",
       "      <td>-0.162210</td>\n",
       "      <td>-0.066568</td>\n",
       "      <td>-0.001567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>seems</td>\n",
       "      <td>0.058308</td>\n",
       "      <td>0.057905</td>\n",
       "      <td>0.057312</td>\n",
       "      <td>0.049753</td>\n",
       "      <td>0.022875</td>\n",
       "      <td>0.000329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>picture</td>\n",
       "      <td>-0.196906</td>\n",
       "      <td>-0.195273</td>\n",
       "      <td>-0.192866</td>\n",
       "      <td>-0.162143</td>\n",
       "      <td>-0.061171</td>\n",
       "      <td>-0.001151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>completely</td>\n",
       "      <td>-0.277845</td>\n",
       "      <td>-0.275461</td>\n",
       "      <td>-0.271947</td>\n",
       "      <td>-0.227098</td>\n",
       "      <td>-0.081775</td>\n",
       "      <td>-0.001421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>wish</td>\n",
       "      <td>0.173191</td>\n",
       "      <td>0.171640</td>\n",
       "      <td>0.169352</td>\n",
       "      <td>0.140022</td>\n",
       "      <td>0.044374</td>\n",
       "      <td>0.000468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>buying</td>\n",
       "      <td>-0.132197</td>\n",
       "      <td>-0.131083</td>\n",
       "      <td>-0.129441</td>\n",
       "      <td>-0.108471</td>\n",
       "      <td>-0.040331</td>\n",
       "      <td>-0.000792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>babies</td>\n",
       "      <td>0.052494</td>\n",
       "      <td>0.052130</td>\n",
       "      <td>0.051594</td>\n",
       "      <td>0.044805</td>\n",
       "      <td>0.021026</td>\n",
       "      <td>0.000365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>won</td>\n",
       "      <td>0.004960</td>\n",
       "      <td>0.004907</td>\n",
       "      <td>0.004830</td>\n",
       "      <td>0.003848</td>\n",
       "      <td>0.001084</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>tub</td>\n",
       "      <td>-0.166745</td>\n",
       "      <td>-0.165367</td>\n",
       "      <td>-0.163338</td>\n",
       "      <td>-0.137693</td>\n",
       "      <td>-0.054778</td>\n",
       "      <td>-0.000936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>almost</td>\n",
       "      <td>-0.031916</td>\n",
       "      <td>-0.031621</td>\n",
       "      <td>-0.031186</td>\n",
       "      <td>-0.025604</td>\n",
       "      <td>-0.007361</td>\n",
       "      <td>-0.000125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>either</td>\n",
       "      <td>-0.228852</td>\n",
       "      <td>-0.226793</td>\n",
       "      <td>-0.223758</td>\n",
       "      <td>-0.184986</td>\n",
       "      <td>-0.061138</td>\n",
       "      <td>-0.000980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          words  coefficients [L2=0]  coefficients [L2=4]  \\\n",
       "0     intercept            -0.063742            -0.063143   \n",
       "1          baby             0.074073             0.073994   \n",
       "2           one             0.012753             0.012495   \n",
       "3         great             0.801625             0.796897   \n",
       "4          love             1.058554             1.050856   \n",
       "5           use            -0.000104             0.000163   \n",
       "6         would            -0.287021            -0.286027   \n",
       "7          like            -0.003384            -0.003442   \n",
       "8          easy             0.984559             0.977600   \n",
       "9        little             0.524419             0.521385   \n",
       "10         seat            -0.086968            -0.086125   \n",
       "11          old             0.208912             0.207749   \n",
       "12         well             0.453866             0.450969   \n",
       "13          get            -0.196835            -0.196100   \n",
       "14         also             0.158163             0.157246   \n",
       "15       really            -0.017906            -0.017745   \n",
       "16          son             0.128396             0.127761   \n",
       "17         time            -0.072429            -0.072281   \n",
       "18       bought            -0.151817            -0.150917   \n",
       "19      product            -0.263330            -0.262328   \n",
       "20         good             0.156507             0.155270   \n",
       "21     daughter             0.263418             0.261775   \n",
       "22         much            -0.013247            -0.013295   \n",
       "23        loves             1.052484             1.043903   \n",
       "24     stroller            -0.037533            -0.036988   \n",
       "25          put            -0.000330            -0.000323   \n",
       "26       months            -0.067995            -0.067315   \n",
       "27          car             0.193364             0.191904   \n",
       "28        still             0.188508             0.187071   \n",
       "29         back            -0.268954            -0.267419   \n",
       "..          ...                  ...                  ...   \n",
       "164     started            -0.153174            -0.151852   \n",
       "165    anything            -0.186801            -0.185242   \n",
       "166        last            -0.099469            -0.098692   \n",
       "167     company            -0.276548            -0.274151   \n",
       "168        come            -0.032009            -0.031804   \n",
       "169    returned            -0.572707            -0.567518   \n",
       "170       maybe            -0.224076            -0.222015   \n",
       "171        took            -0.046445            -0.046199   \n",
       "172       broke            -0.555195            -0.550209   \n",
       "173       makes            -0.009023            -0.008764   \n",
       "174        stay            -0.300563            -0.297920   \n",
       "175     instead            -0.193123            -0.191418   \n",
       "176        idea            -0.465370            -0.461130   \n",
       "177        head            -0.110472            -0.109559   \n",
       "178        said            -0.098049            -0.097331   \n",
       "179        less            -0.136801            -0.135652   \n",
       "180        went            -0.106836            -0.106003   \n",
       "181     working            -0.320363            -0.317559   \n",
       "182        high             0.003326             0.003282   \n",
       "183        unit            -0.196121            -0.194516   \n",
       "184       seems             0.058308             0.057905   \n",
       "185     picture            -0.196906            -0.195273   \n",
       "186  completely            -0.277845            -0.275461   \n",
       "187        wish             0.173191             0.171640   \n",
       "188      buying            -0.132197            -0.131083   \n",
       "189      babies             0.052494             0.052130   \n",
       "190         won             0.004960             0.004907   \n",
       "191         tub            -0.166745            -0.165367   \n",
       "192      almost            -0.031916            -0.031621   \n",
       "193      either            -0.228852            -0.226793   \n",
       "\n",
       "     coefficients [L2=10]  coefficients [L2=1e2]  coefficients [L2=1e3]  \\\n",
       "0               -0.062256              -0.050438               0.000054   \n",
       "1                0.073877               0.072360               0.059752   \n",
       "2                0.012115               0.007247              -0.008761   \n",
       "3                0.789935               0.701425               0.376012   \n",
       "4                1.039529               0.896644               0.418354   \n",
       "5                0.000556               0.005481               0.017326   \n",
       "6               -0.284564              -0.265993              -0.188662   \n",
       "7               -0.003527              -0.004635              -0.007043   \n",
       "8                0.967362               0.838245               0.401904   \n",
       "9                0.516917               0.460235               0.251221   \n",
       "10              -0.084883              -0.069109              -0.017718   \n",
       "11               0.206037               0.184332               0.105074   \n",
       "12               0.446700               0.392304               0.194926   \n",
       "13              -0.195017              -0.181251              -0.122728   \n",
       "14               0.155899               0.139153               0.080918   \n",
       "15              -0.017508              -0.014481              -0.004448   \n",
       "16               0.126828               0.115192               0.070411   \n",
       "17              -0.072065              -0.069480              -0.057581   \n",
       "18              -0.149594              -0.132884              -0.072431   \n",
       "19              -0.260854              -0.242391              -0.167962   \n",
       "20               0.153445               0.129972               0.047879   \n",
       "21               0.259357               0.228685               0.117158   \n",
       "22              -0.013366              -0.014326              -0.015219   \n",
       "23               1.031265               0.870794               0.345870   \n",
       "24              -0.036186              -0.025990               0.005912   \n",
       "25              -0.000312              -0.000127               0.001529   \n",
       "26              -0.066314              -0.053594              -0.013083   \n",
       "27               0.189754               0.162531               0.072719   \n",
       "28               0.184955               0.158163               0.068491   \n",
       "29              -0.265161              -0.236730              -0.134671   \n",
       "..                    ...                    ...                    ...   \n",
       "164             -0.149905              -0.125084              -0.045084   \n",
       "165             -0.182943              -0.153602              -0.057284   \n",
       "166             -0.097547              -0.083001              -0.034797   \n",
       "167             -0.270621              -0.225839              -0.084898   \n",
       "168             -0.031502              -0.027685              -0.014185   \n",
       "169             -0.559870              -0.462056              -0.150021   \n",
       "170             -0.218976              -0.180192              -0.058149   \n",
       "171             -0.045838              -0.041422              -0.025566   \n",
       "172             -0.542861              -0.448989              -0.148726   \n",
       "173             -0.008382              -0.003467               0.008757   \n",
       "174             -0.294024              -0.244247              -0.083709   \n",
       "175             -0.188907              -0.156863              -0.054125   \n",
       "176             -0.454879              -0.374890              -0.118469   \n",
       "177             -0.108215              -0.090992              -0.032986   \n",
       "178             -0.096274              -0.082875              -0.037594   \n",
       "179             -0.133958              -0.112360              -0.042260   \n",
       "180             -0.104776              -0.089294              -0.039417   \n",
       "181             -0.313427              -0.260764              -0.092334   \n",
       "182              0.003217               0.002404               0.000236   \n",
       "183             -0.192153              -0.162210              -0.066568   \n",
       "184              0.057312               0.049753               0.022875   \n",
       "185             -0.192866              -0.162143              -0.061171   \n",
       "186             -0.271947              -0.227098              -0.081775   \n",
       "187              0.169352               0.140022               0.044374   \n",
       "188             -0.129441              -0.108471              -0.040331   \n",
       "189              0.051594               0.044805               0.021026   \n",
       "190              0.004830               0.003848               0.001084   \n",
       "191             -0.163338              -0.137693              -0.054778   \n",
       "192             -0.031186              -0.025604              -0.007361   \n",
       "193             -0.223758              -0.184986              -0.061138   \n",
       "\n",
       "     coefficients [L2=1e5]  \n",
       "0                 0.011362  \n",
       "1                 0.001784  \n",
       "2                -0.001827  \n",
       "3                 0.008950  \n",
       "4                 0.009042  \n",
       "5                 0.000418  \n",
       "6                -0.008127  \n",
       "7                -0.000827  \n",
       "8                 0.008808  \n",
       "9                 0.005941  \n",
       "10                0.000611  \n",
       "11                0.002741  \n",
       "12                0.003945  \n",
       "13               -0.004578  \n",
       "14                0.001929  \n",
       "15               -0.000340  \n",
       "16                0.001552  \n",
       "17               -0.002805  \n",
       "18               -0.001985  \n",
       "19               -0.006211  \n",
       "20                0.000266  \n",
       "21                0.002401  \n",
       "22               -0.000839  \n",
       "23                0.006150  \n",
       "24                0.001326  \n",
       "25               -0.000097  \n",
       "26               -0.000157  \n",
       "27                0.001765  \n",
       "28                0.000976  \n",
       "29               -0.003988  \n",
       "..                     ...  \n",
       "164              -0.000877  \n",
       "165              -0.001053  \n",
       "166              -0.000775  \n",
       "167              -0.001719  \n",
       "168              -0.000426  \n",
       "169              -0.002225  \n",
       "170              -0.000945  \n",
       "171              -0.000772  \n",
       "172              -0.002182  \n",
       "173               0.000255  \n",
       "174              -0.001310  \n",
       "175              -0.000925  \n",
       "176              -0.001627  \n",
       "177              -0.000502  \n",
       "178              -0.000947  \n",
       "179              -0.000873  \n",
       "180              -0.001006  \n",
       "181              -0.001674  \n",
       "182              -0.000062  \n",
       "183              -0.001567  \n",
       "184               0.000329  \n",
       "185              -0.001151  \n",
       "186              -0.001421  \n",
       "187               0.000468  \n",
       "188              -0.000792  \n",
       "189               0.000365  \n",
       "190               0.000017  \n",
       "191              -0.000936  \n",
       "192              -0.000125  \n",
       "193              -0.000980  \n",
       "\n",
       "[194 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_coefficients_to_table(coefficients_0_penalty, 'coefficients [L2=0]')\n",
    "add_coefficients_to_table(coefficients_4_penalty, 'coefficients [L2=4]')\n",
    "add_coefficients_to_table(coefficients_10_penalty, 'coefficients [L2=10]')\n",
    "add_coefficients_to_table(coefficients_1e2_penalty, 'coefficients [L2=1e2]')\n",
    "add_coefficients_to_table(coefficients_1e3_penalty, 'coefficients [L2=1e3]')\n",
    "add_coefficients_to_table(coefficients_1e5_penalty, 'coefficients [L2=1e5]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using **the coefficients trained with L2 penalty 0**, find the 5 most positive words (with largest positive coefficients). Save them to **positive_words**. Similarly, find the 5 most negative words (with largest negative coefficients) and save them to **negative_words**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Five most positive words (L2=0):\n",
      " 4        love\n",
      "23      loves\n",
      "8        easy\n",
      "34    perfect\n",
      "3       great\n",
      "Name: words, dtype: object\n"
     ]
    }
   ],
   "source": [
    "positive_words = table.sort_values(by='coefficients [L2=0]', ascending = False)[0:5]['words']\n",
    "print(\"Five most positive words (L2=0):\\n\", positive_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Five most negative words (L2=0):\n",
      " 106    disappointed\n",
      "97            money\n",
      "114          return\n",
      "113           waste\n",
      "169        returned\n",
      "Name: words, dtype: object\n"
     ]
    }
   ],
   "source": [
    "negative_words = table.sort_values(by='coefficients [L2=0]', ascending = True)[0:5]['words']\n",
    "print(\"Five most negative words (L2=0):\\n\", negative_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us observe the effect of increasing L2 penalty on the 10 words just selected. We provide you with a utility function to plot the coefficient path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_coefficient_plot(table, positive_words, negative_words, l2_penalty_list):\n",
    "    plt.rcParams['figure.figsize'] = 10, 6\n",
    "    cmap_positive = plt.get_cmap('Reds')\n",
    "    cmap_negative = plt.get_cmap('Blues')\n",
    "    \n",
    "    xx = l2_penalty_list\n",
    "    plt.plot(xx, [0.]*len(xx), '--', lw=1, color='k')\n",
    "    \n",
    "    table_positive_words = table[table['words'].isin(positive_words)]\n",
    "    table_negative_words = table[table['words'].isin(negative_words)]\n",
    "    del table_positive_words['words']\n",
    "    del table_negative_words['words']\n",
    "    \n",
    "    for i in range(len(positive_words)):\n",
    "        color = cmap_positive(0.8*((i+1)/(len(positive_words)*1.2)+0.15))\n",
    "        plt.plot(xx, table_positive_words[i:i+1].as_matrix().flatten(),\n",
    "                 '-', label=positive_words.values[i], linewidth=4.0, color=color)\n",
    "        \n",
    "    for i in range(len(negative_words)):\n",
    "        color = cmap_negative(0.8*((i+1)/(len(negative_words)*1.2)+0.15))\n",
    "        plt.plot(xx, table_negative_words[i:i+1].as_matrix().flatten(),\n",
    "                 '-', label=negative_words.values[i], linewidth=4.0, color=color)\n",
    "        \n",
    "    plt.legend(loc='best', ncol=3, prop={'size':16}, columnspacing=0.5)\n",
    "    plt.axis([1, 1e5, -1, 2])\n",
    "    plt.title('Coefficient path')\n",
    "    plt.xlabel('L2 penalty ($\\lambda$)')\n",
    "    plt.ylabel('Coefficient value')\n",
    "    plt.xscale('log')\n",
    "    plt.rcParams.update({'font.size': 18})\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArcAAAGXCAYAAACp2XjcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x134905b0748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# Compare coefficients\n",
    "make_coefficient_plot(table, positive_words, negative_words, l2_penalty_list=[0, 4, 10, 1e2, 1e3, 1e5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us compute the accuracy of the classifier model. Recall that the accuracy is given by\n",
    "$$\n",
    "\\mbox{accuracy} = \\frac{\\mbox{# correctly classified data points}}{\\mbox{# total data points}}\n",
    "$$\n",
    "Recall from lecture that that the class prediction is calculated using $$\n",
    "\\hat{y}_i = \n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "      +1 & h(\\mathbf{x}_i)^T\\mathbf{w} > 0 \\\\\n",
    "      -1 & h(\\mathbf{x}_i)^T\\mathbf{w} \\leq 0 \\\\\n",
    "\\end{array} \n",
    "\\right.\n",
    "$$\n",
    "**Note**: It is important to know that the model prediction code doesn't change even with the addition of an L2 penalty. The only thing that changes is the estimated coefficients used in this prediction.\n",
    "Based on the above, we will use the same code that was used in Module 3 assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_classification_accuracy(feature_matrix, sentiment, coefficients):\n",
    "    scores = np.dot(feature_matrix, coefficients)\n",
    "    apply_threshold = np.vectorize(lambda x: 1. if x > 0  else -1.)\n",
    "    predictions = apply_threshold(scores)\n",
    "    \n",
    "    num_correct = (predictions == sentiment).sum()\n",
    "    accuracy = num_correct / len(feature_matrix)    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_accuracy = {}\n",
    "train_accuracy[0]   = get_classification_accuracy(feature_matrix_train, sentiment_train, coefficients_0_penalty)\n",
    "train_accuracy[4]   = get_classification_accuracy(feature_matrix_train, sentiment_train, coefficients_4_penalty)\n",
    "train_accuracy[10]  = get_classification_accuracy(feature_matrix_train, sentiment_train, coefficients_10_penalty)\n",
    "train_accuracy[1e2] = get_classification_accuracy(feature_matrix_train, sentiment_train, coefficients_1e2_penalty)\n",
    "train_accuracy[1e3] = get_classification_accuracy(feature_matrix_train, sentiment_train, coefficients_1e3_penalty)\n",
    "train_accuracy[1e5] = get_classification_accuracy(feature_matrix_train, sentiment_train, coefficients_1e5_penalty)\n",
    "\n",
    "validation_accuracy = {}\n",
    "validation_accuracy[0]   = get_classification_accuracy(feature_matrix_valid, sentiment_valid, coefficients_0_penalty)\n",
    "validation_accuracy[4]   = get_classification_accuracy(feature_matrix_valid, sentiment_valid, coefficients_4_penalty)\n",
    "validation_accuracy[10]  = get_classification_accuracy(feature_matrix_valid, sentiment_valid, coefficients_10_penalty)\n",
    "validation_accuracy[1e2] = get_classification_accuracy(feature_matrix_valid, sentiment_valid, coefficients_1e2_penalty)\n",
    "validation_accuracy[1e3] = get_classification_accuracy(feature_matrix_valid, sentiment_valid, coefficients_1e3_penalty)\n",
    "validation_accuracy[1e5] = get_classification_accuracy(feature_matrix_valid, sentiment_valid, coefficients_1e5_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 penalty = 0\n",
      "train accuracy = 0.785156157787, validation_accuracy = 0.78143964149\n",
      "---------------------------------------------------------------------\n",
      "L2 penalty = 4\n",
      "train accuracy = 0.785108944548, validation_accuracy = 0.781533003454\n",
      "---------------------------------------------------------------------\n",
      "L2 penalty = 10\n",
      "train accuracy = 0.784990911452, validation_accuracy = 0.781719727383\n",
      "---------------------------------------------------------------------\n",
      "L2 penalty = 100\n",
      "train accuracy = 0.783975826822, validation_accuracy = 0.781066193633\n",
      "---------------------------------------------------------------------\n",
      "L2 penalty = 1000\n",
      "train accuracy = 0.775855149784, validation_accuracy = 0.771356549342\n",
      "---------------------------------------------------------------------\n",
      "L2 penalty = 100000\n",
      "train accuracy = 0.680366374731, validation_accuracy = 0.667818130893\n",
      "---------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Build a simple report\n",
    "for key in sorted(validation_accuracy.keys()):\n",
    "    print(\"L2 penalty = %g\" % key)\n",
    "    print(\"train accuracy = %s, validation_accuracy = %s\" % (train_accuracy[key], validation_accuracy[key]))\n",
    "    print(\"---------------------------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
